{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Kecil\n",
    "## Eksplorasi library Decision Tree Learning pada Jupyter Notebook\n",
    "### Play Tennis\n",
    "<p>Anggota : <br>\n",
    " Jose Galbraith Hasintongan (13519022) <br>\n",
    " Muhammad Fahkry Malta (13519032) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Import libraries yang diperlukan</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Import Play Tennis Dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_tennis = pd.read_csv('play_tennis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Buat dataframe untuk dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_tennis = pd.DataFrame(play_tennis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day   Outlook Temperature Humidity    Wind Play\n",
       "0  D1     Sunny         Hot     High    Weak   No\n",
       "1  D2     Sunny         Hot     High  Strong   No\n",
       "2  D3  Overcast         Hot     High    Weak  Yes\n",
       "3  D4      Rain        Mild     High    Weak  Yes\n",
       "4  D5      Rain        Cool   Normal    Weak  Yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_tennis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Outlook', 'Temperature', 'Humidity', 'Wind', 'Play'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_tennis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Split Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "df_play_tennis['Outlook'] = lb.fit_transform(df_play_tennis['Outlook']) \n",
    "df_play_tennis['Temperature'] = lb.fit_transform(df_play_tennis['Temperature'] ) \n",
    "df_play_tennis['Humidity'] = lb.fit_transform(df_play_tennis['Humidity'] ) \n",
    "df_play_tennis['Wind'] = lb.fit_transform(df_play_tennis['Wind'] )   \n",
    "df_play_tennis['Play'] = lb.fit_transform(df_play_tennis['Play'] ) \n",
    "X = df_play_tennis.iloc[:,1:5] \n",
    "y = df_play_tennis.iloc[:,5]\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(165.33333333333334, 338.79999999999995, 'X[0] <= 0.5\\nentropy = 0.496\\nsamples = 11\\nvalue = [5, 6]'),\n",
       " Text(82.66666666666667, 277.2, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(248.0, 277.2, 'X[1] <= 1.5\\nentropy = 0.469\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(165.33333333333334, 215.59999999999997, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(330.6666666666667, 215.59999999999997, 'X[2] <= 0.5\\nentropy = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(248.0, 154.0, 'X[0] <= 1.5\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(165.33333333333334, 92.39999999999998, 'X[3] <= 0.5\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(82.66666666666667, 30.80000000000001, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(248.0, 30.80000000000001, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(330.6666666666667, 92.39999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(413.33333333333337, 154.0, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf1 = clf1.fit(X_train,y_train)\n",
    "tree.plot_tree(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_tennis_columns = df_play_tennis.columns[1:5]\n",
    "play_tennis_columns_ = []\n",
    "for i in play_tennis_columns:\n",
    "    play_tennis_columns_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outlook', 'Temperature', 'Humidity', 'Wind'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_tennis.columns[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Outlook <= 0.50\n",
      "|   |--- class: 1\n",
      "|--- Outlook >  0.50\n",
      "|   |--- Temperature <= 1.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- Temperature >  1.50\n",
      "|   |   |--- Humidity <= 0.50\n",
      "|   |   |   |--- Outlook <= 1.50\n",
      "|   |   |   |   |--- Wind <= 0.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- Wind >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- Outlook >  1.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- Humidity >  0.50\n",
      "|   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Export Text\n",
    "r1 = export_text(clf1, feature_names=play_tennis_columns_)\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.3333333333333333\n",
      "F1 Score :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "print(\"Accuracy score : \", sklearn.metrics.accuracy_score(y_test, clf1.predict(X_test)))\n",
    "print(\"F1 Score : \", sklearn.metrics.f1_score(y_test, clf1.predict(X_test),average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decision-tree-id3 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nose>=1.1.2 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (from decision-tree-id3) (1.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.17 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (from decision-tree-id3) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (from decision-tree-id3) (1.16.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17->decision-tree-id3) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\fahkry\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17->decision-tree-id3) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install decision-tree-id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train,y_train)\n",
    "tree = export_graphviz(estimator.tree_, 'play-tennis.dot', df_play_tennis.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpdf play-tennis.dot -o play-tennis.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.3333333333333333\n",
      "F1 Score :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "print(\"Accuracy score : \", sklearn.metrics.accuracy_score(y_test, estimator.predict(X_test)))\n",
    "print(\"F1 Score : \", sklearn.metrics.f1_score(y_test, estimator.predict(X_test),average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>K Means</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 0.33333333 0.83333333 0.66666667]\n",
      " [1.375      1.75       0.25       0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "x1 = df_play_tennis.iloc[:,1:5]\n",
    "y1 = df_play_tennis.iloc[:,5]\n",
    "X_train1, X_test1, y_train1, y_test1 = sklearn.model_selection.train_test_split(x1, y1, random_state=0)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(x1)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.25\n",
      "F1 Score :  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \" , sklearn.metrics.accuracy_score(y_test1, kmeans.predict(X_test1)))\n",
    "print(\"F1 Score : \" , sklearn.metrics.f1_score(y_test1, kmeans.predict(X_test1),average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.3333333333333333\n",
      "F1 Score :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy score : \" , sklearn.metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "print(\"F1 Score : \" , sklearn.metrics.f1_score(y_test, model.predict(X_test),average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Neural Network</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.6666666666666666\n",
      "F1 Score :  0.8000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf4 = MLPClassifier(random_state=1, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Accuracy score : \" , sklearn.metrics.accuracy_score(y_test, clf4.predict(X_test)))\n",
    "print(\"F1 Score : \" , sklearn.metrics.f1_score(y_test, clf4.predict(X_test),average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.3333333333333333\n",
      "F1 Score :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahkry\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "model2 = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "model2.fit(X_train, y_train)\n",
    "# print(model2.predict([[-0.8, -1]]))\n",
    "print(\"Accuracy score : \" , sklearn.metrics.accuracy_score(y_test, model2.predict(X_test)))\n",
    "print(\"F1 Score : \" , sklearn.metrics.f1_score(y_test, model2.predict(X_test),average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c0be557704733567a7c5ca28a0f122c28c34ba6b7fc5b075adcbb642e468030"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
