{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan informasi WHO, stroke merupakan penyebab kematian terbanyak nomor 2 di dunia dan menjadi penyebab dari 11% total kematian. [Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) ini digunakan untuk memprediksi apakah seorang pasien memiliki kemungkinan besar untuk terkena stroke berdasarkan informasi tentang pasien seperti jenis kelamin, umur, penyakit dan status merokok.\n",
    "\n",
    "Tujuan eksperimen:\n",
    "1.   Peserta memahami rangkaian proses analitika data menggunakan pendekatan pembelajaran mesin. \n",
    "2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hiperparameternya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n",
    "3. Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitika menggunakan pendekatan pembelajaran mesin.\n",
    "\n",
    "Praktikum dilaksanakan secara berkelompok, dengan 1 kelompok terdiri atas 2 mahasiswa. Soal praktikum terdapat di bagian bawah berkas ini. Harap diperhatikan bahwa terdapat berkas yang harus dikumpulkan sebelum waktu praktikum selesai (4 April 2022 11.00 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai (4 April 2022 23.59 WIB). Untuk detil deliverables dan soal, dapat dilihat pada bagian bawah notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "X = data.drop(columns=\"stroke\")\n",
    "y = data[\"stroke\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soal Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disediakan data yang sudah dibagi menjadi data train (df_train), validasi (df_val), dan test (df_test). Lakukanlah:\n",
    "1. Buatlah baseline dengan menggunakan model Logistic Regression\n",
    "2. Lakukan analisa data terkait:\n",
    "- Duplicate value\n",
    "- Missing value\n",
    "- Outlier\n",
    "- Balance of data\n",
    "3. Jelaskan bagaimana kalian akan menangani permasalahan yang disebutkan pada poin 2\n",
    "4. Sebutkan dan jelaskan alasan dari teknik encoding yang akan kalian gunakan terhadap data tersebut\n",
    "5. Buatlah desain eksperimen dengan menentukan hal berikut:\n",
    "- Tujuan eksperimen\n",
    "- Dependent dan Independent variabel\n",
    "- Strategi eksperimen\n",
    "- Skema validasi\n",
    "6. Implementasikan strategi eksperimen dan skema validasi yang sudah kalian buat\n",
    "7. Berdasarkan hasil prediksi yang kalian hasilkan, buatlah kesimpulan analisis karakteristik pasien yang terkena stroke\n",
    "\n",
    "Poin 1 - 5 dikerjakan saat praktikum berlangsung (pukul 09.00 WIB - 11.00 WIB)\n",
    "Poin 6 - 7 dikerjakan saat setelah praktikum berlangsung (pukul 11.00 WIB - 23.59 WIB)\n",
    "\n",
    "Jika terdapat perubahan jawaban pada poin 1 - 5 (semisal perbedaan cara melakukan handling missing value), dapat dijelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan merubah jawaban tersebut (semisal menemukan suatu hal menarik pada data, sehingga missing value dapat dihandle dengan metode yang lebih bagus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ubah categorical \n",
    "lb = LabelEncoder()\n",
    "df_train['gender'] = lb.fit_transform(df_train['gender'] ) \n",
    "df_val['gender'] = lb.fit_transform(df_val['gender'] ) \n",
    "df_test['gender'] = lb.fit_transform(df_test['gender'] ) \n",
    "\n",
    "df_train['ever_married'] = lb.fit_transform(df_train['ever_married'] ) \n",
    "df_val['ever_married'] = lb.fit_transform(df_val['ever_married'] ) \n",
    "df_test['ever_married'] = lb.fit_transform(df_test['ever_married'] ) \n",
    "\n",
    "df_train['work_type'] = lb.fit_transform(df_train['work_type'] ) \n",
    "df_val['work_type'] = lb.fit_transform(df_val['work_type'] ) \n",
    "df_test['work_type'] = lb.fit_transform(df_test['work_type'] ) \n",
    "\n",
    "df_train['work_type'] = lb.fit_transform(df_train['work_type'] ) \n",
    "df_val['work_type'] = lb.fit_transform(df_val['work_type'] ) \n",
    "df_test['work_type'] = lb.fit_transform(df_test['work_type'] ) \n",
    "\n",
    "df_train['Residence_type'] = lb.fit_transform(df_train['Residence_type'] ) \n",
    "df_val['Residence_type'] = lb.fit_transform(df_val['Residence_type']) \n",
    "df_test['Residence_type'] = lb.fit_transform(df_test['Residence_type']) \n",
    "\n",
    "df_train['smoking_status'] = lb.fit_transform(df_train['smoking_status'] ) \n",
    "df_val['smoking_status'] = lb.fit_transform(df_val['smoking_status']) \n",
    "df_test['smoking_status'] = lb.fit_transform(df_test['smoking_status']) \n",
    "\n",
    "\n",
    "df_train['gender'] = lb.fit_transform(df_train['gender'] ) \n",
    "df_val['gender'] = lb.fit_transform(df_val['gender'] ) \n",
    "df_test['gender'] = lb.fit_transform(df_test['gender'] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['bmi'].fillna(df_train['bmi'].mean(), inplace= True)\n",
    "df_test['bmi'].fillna(df_test['bmi'].mean(), inplace= True)\n",
    "df_val['bmi'].fillna(df_val['bmi'].mean(), inplace= True)\n",
    "model = LogisticRegression()\n",
    "# model.fit(df_train, y_train)\n",
    "# model.predict(X_val)\n",
    "df_train['gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lakukan analisa data terkait:\n",
    "- Duplicate value\n",
    "- Missing value\n",
    "- Outlier\n",
    "- Balance of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate value: \n",
      " Data train duplicate value:  0\n",
      " Data validasi duplicate value:  0\n",
      " Data test duplicate value:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate value: \")\n",
    "print(\" Data train duplicate value: \", df_train.duplicated().sum())\n",
    "print(\" Data validasi duplicate value: \", df_val.duplicated().sum())\n",
    "print(\" Data test duplicate value: \", df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value: \n",
      " Data train missing value:  id                     0\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  130\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value: \")\n",
    "print(\" Data train missing value: \", df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data validasi missing value:  id                    0\n",
      "gender                0\n",
      "age                   0\n",
      "hypertension          0\n",
      "heart_disease         0\n",
      "ever_married          0\n",
      "work_type             0\n",
      "Residence_type        0\n",
      "avg_glucose_level     0\n",
      "bmi                  35\n",
      "smoking_status        0\n",
      "stroke                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" Data validasi missing value: \", df_val.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data test missing value:  id                    0\n",
      "gender                0\n",
      "age                   0\n",
      "hypertension          0\n",
      "heart_disease         0\n",
      "ever_married          0\n",
      "work_type             0\n",
      "Residence_type        0\n",
      "avg_glucose_level     0\n",
      "bmi                  36\n",
      "smoking_status        0\n",
      "stroke                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" Data test missing value: \", df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier: \n",
      "Outlier Data Train: \n",
      "id: 0\n",
      "gender: 0\n",
      "age: 0\n",
      "hypertension: 6244\n",
      "heart_disease: 6355\n",
      "ever_married: 0\n",
      "work_type: 427\n",
      "Residence_type: 0\n",
      "avg_glucose_level: 414\n",
      "bmi: 91\n",
      "smoking_status: 0\n",
      "stroke: 6379\n"
     ]
    }
   ],
   "source": [
    "print(\"Outlier: \")\n",
    "print(\"Outlier Data Train: \")\n",
    "def outlier_data_train(column):\n",
    "    Q1 = np.percentile(df_train[column], 25,\n",
    "                    interpolation = 'midpoint')\n",
    "    \n",
    "    Q3 = np.percentile(df_train[column], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = df_train[column] >= (Q3+1.5*IQR)\n",
    "    count_upper = len(np.where(upper)[0])\n",
    "\n",
    "    lower = df_train[column] <= (Q1-1.5*IQR)\n",
    "    count_lower = len(np.where(lower)[0])\n",
    "\n",
    "    count_outlier = count_upper + count_lower\n",
    "    return(count_outlier)\n",
    "\n",
    "for col in df_train.columns:\n",
    "    print(col + \": \" + str(outlier_data_train(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Data Validasi: \n",
      "id: 0\n",
      "gender: 0\n",
      "age: 0\n",
      "hypertension: 1550\n",
      "heart_disease: 1592\n",
      "ever_married: 0\n",
      "work_type: 107\n",
      "Residence_type: 0\n",
      "avg_glucose_level: 106\n",
      "bmi: 20\n",
      "smoking_status: 0\n",
      "stroke: 1598\n"
     ]
    }
   ],
   "source": [
    "print(\"Outlier Data Validasi: \")\n",
    "def outlier_data_validasi(column):\n",
    "    Q1 = np.percentile(df_val[column], 25,\n",
    "                    interpolation = 'midpoint')\n",
    "    \n",
    "    Q3 = np.percentile(df_val[column], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = df_val[column] >= (Q3+1.5*IQR)\n",
    "    count_upper = len(np.where(upper)[0])\n",
    "\n",
    "    lower = df_val[column] <= (Q1-1.5*IQR)\n",
    "    count_lower = len(np.where(lower)[0])\n",
    "\n",
    "    count_outlier = count_upper + count_lower\n",
    "    return(count_outlier)\n",
    "\n",
    "for col in df_val.columns:\n",
    "    print(col + \": \" + str(outlier_data_validasi(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Data Test: \n",
      "id: 0\n",
      "gender: 0\n",
      "age: 0\n",
      "hypertension: 1928\n",
      "heart_disease: 1997\n",
      "ever_married: 0\n",
      "work_type: 123\n",
      "Residence_type: 0\n",
      "avg_glucose_level: 101\n",
      "bmi: 19\n",
      "smoking_status: 0\n",
      "stroke: 1994\n"
     ]
    }
   ],
   "source": [
    "print(\"Outlier Data Test: \")\n",
    "def outlier_data_test(column):\n",
    "    Q1 = np.percentile(df_test[column], 25,\n",
    "                    interpolation = 'midpoint')\n",
    "    \n",
    "    Q3 = np.percentile(df_test[column], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = df_test[column] >= (Q3+1.5*IQR)\n",
    "    count_upper = len(np.where(upper)[0])\n",
    "\n",
    "    lower = df_test[column] <= (Q1-1.5*IQR)\n",
    "    count_lower = len(np.where(lower)[0])\n",
    "\n",
    "    count_outlier = count_upper + count_lower\n",
    "    return(count_outlier)\n",
    "\n",
    "for col in df_test.columns:\n",
    "    print(col + \": \" + str(outlier_data_test(col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jelaskan pembagian tugas/ kerja antar anggota kelompok saat eksperimen,  pada sel ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook dengan nama file PraktikumIF3270_M1_NIM1_NIM2.ipynb untuk poin 1 - 5.\n",
    "2. Notebook dengan nama file PraktikumIF3270_M2_NIM1_NIM2.ipynb yang merupakan kelanjutan dari notebook poin 1, dengan tambahan hasil poin 6 dan 7.\n",
    "3. Laporan dengan nama file PraktikumIF3270_NIM1_NIM2.pdf dengan isi sebagai berikut:\n",
    "- Hasil analisa terhadap data, penanganan yang dilakukan serta justifikasi teknik-teknik yang dipilih\n",
    "- Perubahan yang dilakukan pada jawaban poin 1 - 5 jika ada\n",
    "- Desain eksperimen\n",
    "- Hasil eksperimen\n",
    "- Analisis dan kesimpulan\n",
    "- Pembagian Tugas / Kerja antar anggota kelompok\n",
    "\n",
    "Deadline pengumpulan:\n",
    "- Deliverables poin 1 dikumpulkan sebelum <b>pukul 11.00 WIB</b>, Senin 4 April 2022\n",
    "- Deliverables poin 2 dikumpulkan sebelum <b>pukul 23.59 WIB</b>, Senin 4 April 2022\n",
    "- Deliverables poin 3 dikumpulkan sebelum <b>pukul 23.59 WIB</b>, Senin 4 April 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
