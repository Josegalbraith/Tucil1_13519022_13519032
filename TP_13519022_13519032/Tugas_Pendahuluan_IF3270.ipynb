{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdq8ydSd4xUy"
   },
   "source": [
    "# Tugas Pendahuluan\n",
    "Tugas Pendahuluan dikerjakan dengan dataset titanic yang dapat didownload pada link [berikut](https://drive.google.com/file/d/16j_9FEHLjh_Y_3CdUtp9M13VwImyT89T/view?usp=sharing). Lakukan prediksi apakah suatu penumpang selamat atau tidak (kolom **survived**), bernilai 0 jika tidak selamat, dan 1 jika selamat.\n",
    "\n",
    "<br>\n",
    "Tugas dikerjakan secara berkelompok, dengan 1 kelompok terdiri atas 2 mahasiswa. Waktu pengerjaan dari 28 Maret 2022 - 3 April 2022 pukul 23.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAHqneEY7b7b"
   },
   "source": [
    "# 0. Loading Data and Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "zsBbpcIi7fHi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "OWLkjeKo7gdD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Abelseth, Miss. Karen Marie</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348125</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Burns, Miss. Mary Delia</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330963</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>de Messemaeker, Mrs. Guillaume Joseph (Emma)</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345572</td>\n",
       "      <td>17.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jonsson, Mr. Nils Hilding</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350408</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dahl, Mr. Karl Edwart</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7598</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Penasco y Castellana, Mr. Victor de Satode</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Becker, Miss. Ruth Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230136</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>F4</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1307</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Murphy, Miss. Katherine \"Kate\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367230</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1308</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  pclass  survived                                          name  \\\n",
       "0         0     3.0       1.0                   Abelseth, Miss. Karen Marie   \n",
       "1         1     3.0       0.0                       Burns, Miss. Mary Delia   \n",
       "2         2     1.0       1.0                Fortune, Miss. Alice Elizabeth   \n",
       "3         3     3.0       1.0  de Messemaeker, Mrs. Guillaume Joseph (Emma)   \n",
       "4         4     3.0       0.0                     Jonsson, Mr. Nils Hilding   \n",
       "...     ...     ...       ...                                           ...   \n",
       "1304   1304     3.0       1.0                         Dahl, Mr. Karl Edwart   \n",
       "1305   1305     1.0       0.0    Penasco y Castellana, Mr. Victor de Satode   \n",
       "1306   1306     2.0       1.0                  Becker, Miss. Ruth Elizabeth   \n",
       "1307   1307     3.0       1.0                Murphy, Miss. Katherine \"Kate\"   \n",
       "1308   1308     3.0       0.0                           Sage, Mr. Frederick   \n",
       "\n",
       "         sex   age  sibsp  parch    ticket      fare        cabin embarked  \n",
       "0     female  16.0    0.0    0.0    348125    7.6500          NaN        S  \n",
       "1     female  18.0    0.0    0.0    330963    7.8792          NaN        Q  \n",
       "2     female  24.0    3.0    2.0     19950  263.0000  C23 C25 C27        S  \n",
       "3     female  36.0    1.0    0.0    345572   17.4000          NaN        S  \n",
       "4       male  27.0    0.0    0.0    350408    7.8542          NaN        S  \n",
       "...      ...   ...    ...    ...       ...       ...          ...      ...  \n",
       "1304    male  45.0    0.0    0.0      7598    8.0500          NaN        S  \n",
       "1305    male  18.0    1.0    0.0  PC 17758  108.9000          C65        C  \n",
       "1306  female  12.0    2.0    1.0    230136   39.0000           F4        S  \n",
       "1307  female   NaN    1.0    0.0    367230   15.5000          NaN        Q  \n",
       "1308    male   NaN    8.0    2.0  CA. 2343   69.5500          NaN        S  \n",
       "\n",
       "[1309 rows x 12 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYGzyrantR1r"
   },
   "source": [
    "# I. Data Understanding\n",
    "Tujuan dari bagian ini adalah peserta dapat memahami kualitas dari data yang diberikan. Hal ini meliputi:\n",
    "1. Ukuran data\n",
    "2. Statistik dari tiap fitur\n",
    "3. Pencilan (outlier)\n",
    "4. Korelasi\n",
    "5. Distribusi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SMf9-ikuoCe"
   },
   "source": [
    "## I.1 \n",
    "Carilah:\n",
    "1. Ukuran dari data (instances dan features)\n",
    "2. Tipe dari tiap-tiap fitur \n",
    "3. Banyaknya unique values dari fitur yang bertipe kategorikal\n",
    "4. Nilai minimum, maksimum, rata-rata, median, dan standar deviasi dari fitur yang tidak bertipe kategorikal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "id": "SAxrfZySuM3-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Ukuran dari data: instances = 1309 , feature = 12\n",
      "\n",
      "2. Tipe dari tiap-tiap fitur: \n",
      "index         int64\n",
      "pclass      float64\n",
      "survived    float64\n",
      "name         object\n",
      "sex          object\n",
      "age         float64\n",
      "sibsp       float64\n",
      "parch       float64\n",
      "ticket       object\n",
      "fare        float64\n",
      "cabin        object\n",
      "embarked     object\n",
      "dtype: object\n",
      "\n",
      "3. Banyaknya unique values dari fitur yang bertipe kategorikal: \n",
      "name        1307\n",
      "sex            2\n",
      "ticket       929\n",
      "cabin        186\n",
      "embarked       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "instance = len(df)\n",
    "features = len(df.columns)\n",
    "feature_type = df.dtypes\n",
    "df_categ = df[['name', 'sex', 'ticket', 'cabin', 'embarked']].copy()\n",
    "df_noncateg = df[['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare']].copy()\n",
    "# uniqueValues = (df['name'].append(df['sex']).append(df['ticket']).append(df['cabin']).append(df['embarked'])).nunique()\n",
    "uniqueValues2 = df_categ.nunique()\n",
    "mini = df_noncateg.min()\n",
    "maks = df_noncateg.max()\n",
    "rata_rata = df_noncateg.mean()\n",
    "med = df_noncateg.median()\n",
    "std_dev = df_noncateg.std()\n",
    "\n",
    "print(\"1. Ukuran dari data: instances = \" + str(instance) + \" , feature = \" + str(features))\n",
    "print()\n",
    "print(\"2. Tipe dari tiap-tiap fitur: \")\n",
    "print(feature_type)\n",
    "print()\n",
    "print(\"3. Banyaknya unique values dari fitur yang bertipe kategorikal: \")\n",
    "# print(uniqueValues)\n",
    "print(uniqueValues2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Nilai minimum, maksimum, rata-rata, median, dan standar deviasi dari fitur yang tidak bertipe kategorikal: \n",
      "\n",
      "Nilai Minimum: \n",
      "pclass      1.0000\n",
      "survived    0.0000\n",
      "age         0.1667\n",
      "sibsp       0.0000\n",
      "parch       0.0000\n",
      "fare        0.0000\n",
      "dtype: float64\n",
      "\n",
      "Nilai Maksimum: \n",
      "pclass        3.0000\n",
      "survived      1.0000\n",
      "age          80.0000\n",
      "sibsp         8.0000\n",
      "parch         9.0000\n",
      "fare        512.3292\n",
      "dtype: float64\n",
      "\n",
      "Nilai Rata-Rata: \n",
      "pclass       2.294882\n",
      "survived     0.381971\n",
      "age         29.881135\n",
      "sibsp        0.498854\n",
      "parch        0.385027\n",
      "fare        33.295479\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"4. Nilai minimum, maksimum, rata-rata, median, dan standar deviasi dari fitur yang tidak bertipe kategorikal: \")\n",
    "print()\n",
    "print(\"Nilai Minimum: \")\n",
    "print(mini)\n",
    "print()\n",
    "print(\"Nilai Maksimum: \")\n",
    "print(maks)\n",
    "print()\n",
    "print(\"Nilai Rata-Rata: \")\n",
    "print(rata_rata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai Median: \n",
      "pclass       3.0000\n",
      "survived     0.0000\n",
      "age         28.0000\n",
      "sibsp        0.0000\n",
      "parch        0.0000\n",
      "fare        14.4542\n",
      "dtype: float64\n",
      "\n",
      "Nilai Standar Deviasi: \n",
      "pclass       0.837836\n",
      "survived     0.486055\n",
      "age         14.413500\n",
      "sibsp        1.041658\n",
      "parch        0.865560\n",
      "fare        51.758668\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nilai Median: \")\n",
    "print(med)\n",
    "print()\n",
    "print(\"Nilai Standar Deviasi: \")\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE1l_gOTwHuz"
   },
   "source": [
    "## I.2\n",
    "Carilah:\n",
    "1. Missing values dari tiap fitur\n",
    "2. Outliers dari tiap fitur (gunakan metode yang kalian ketahui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "IGe-YWAvwQDr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Missing values dari tiap fitur: \n",
      "index          0\n",
      "pclass         0\n",
      "survived       0\n",
      "name           0\n",
      "sex            0\n",
      "age          263\n",
      "sibsp          0\n",
      "parch          0\n",
      "ticket         0\n",
      "fare           1\n",
      "cabin       1014\n",
      "embarked       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "miss_val = df.isnull().sum()\n",
    "print(\"1. Missing values dari tiap fitur: \")\n",
    "print(miss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Outliers dari tiap fitur: \n",
      "pclass: 0\n",
      "survived: 0\n",
      "age: 0\n",
      "sibsp: 57\n",
      "parch: 2311\n",
      "fare: 0\n"
     ]
    }
   ],
   "source": [
    "def outlier(column):\n",
    "    Q1 = np.percentile(df[column], 25,\n",
    "                    interpolation = 'midpoint')\n",
    "    \n",
    "    Q3 = np.percentile(df[column], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = df[column] >= (Q3+1.5*IQR)\n",
    "    count_upper = len(np.where(upper)[0])\n",
    "\n",
    "    lower = df[column] <= (Q1-1.5*IQR)\n",
    "    count_lower = len(np.where(lower)[0])\n",
    "\n",
    "    count_outlier = count_upper + count_lower\n",
    "    return(count_outlier)\n",
    "    # print(np.where(upper))\n",
    "    # print(np.where(lower))\n",
    "\n",
    "print(\"2. Outliers dari tiap fitur: \")\n",
    "\n",
    "for col in df_noncateg.columns:\n",
    "    print(col + \": \" + str(outlier(col)))\n",
    "    # print(col + \": \")\n",
    "    # outlier(col)\n",
    "# outlier('pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tUGStQ_wR4P"
   },
   "source": [
    "## I.3\n",
    "Carilah:\n",
    "1. Korelasi antar fitur\n",
    "2. Visualisasikan distribusi dari tiap fitur (kategorikal dan kontinu)\n",
    "3. Visualisasikan distribusi dari tiap fitur, dengan data dibagi tiap unique values fitur survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "XoBqyQA1wRNX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Korelasi antar fitur: \n",
      "             index    pclass  survived       age     sibsp     parch      fare\n",
      "index     1.000000 -0.003466  0.002967 -0.003376 -0.015501 -0.013538 -0.022424\n",
      "pclass   -0.003466  1.000000 -0.312469 -0.408106  0.060832  0.018322 -0.558629\n",
      "survived  0.002967 -0.312469  1.000000 -0.055513 -0.027825  0.082660  0.244265\n",
      "age      -0.003376 -0.408106 -0.055513  1.000000 -0.243699 -0.150917  0.178739\n",
      "sibsp    -0.015501  0.060832 -0.027825 -0.243699  1.000000  0.373587  0.160238\n",
      "parch    -0.013538  0.018322  0.082660 -0.150917  0.373587  1.000000  0.221539\n",
      "fare     -0.022424 -0.558629  0.244265  0.178739  0.160238  0.221539  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Korelasi antar fitur: \")\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Visualisasi distribusi dari tiap fitur (kategorikal dan kontinu): \n",
      "3. Visualisasi distribusi dari tiap fitur, dengan data dibagi tiap unique values fitur survived\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Visualisasi distribusi dari tiap fitur (kategorikal dan kontinu): \")\n",
    "# print(df.describe(include = \"all\"))\n",
    "# for cat in df_categ:\n",
    "#     df.boxplot(by =cat, column =['pclass'], grid = False)\n",
    "print(\"3. Visualisasi distribusi dari tiap fitur, dengan data dibagi tiap unique values fitur survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV3BDt235mdz"
   },
   "source": [
    "## I.4\n",
    "Lakukanlah analisa pada data lebih lanjut jika dibutuhkan, kemudian lakukanlah:\n",
    "1. Penambahan fitur jika memungkinkan\n",
    "2. Pembuangan fitur yang menurut kalian tidak dibutuhkan\n",
    "3. Penanganan missing values\n",
    "4. Transformasi data kategorikal menjadi numerikal (encoding), dengan metode yang kalian inginkan\n",
    "5. Lakukan scaling dengan MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "id": "jlTGspG_56re"
   },
   "outputs": [],
   "source": [
    "# I.4 Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt2zHZRauLIm"
   },
   "source": [
    "# II. Experiments Design\n",
    "Tujuan dari bagian ini adalah peserta dapat memahami cara melakukan eksperimen mencari metode terbaik dengan benar. Hal ini meliputi:\n",
    "1. Pembuatan model\n",
    "2. Proses validasi\n",
    "3. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kf4xsl8RydIt"
   },
   "source": [
    "## II.1\n",
    "Tentukanlah metrics yang akan digunakan pada eksperimen kali ini (dapat lebih dari 1 metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2I0axfj4OuC"
   },
   "source": [
    "1. Precision\n",
    "2. Recall\n",
    "3. F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FONT0OyUyoQG"
   },
   "source": [
    "## II.2 \n",
    "Bagi data dengan perbandingan 0.8 untuk data train dan 0.2 untuk data validasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "Gqa9nn5muMS2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1304    0\n",
       "1305    0\n",
       "1306    1\n",
       "1307    1\n",
       "1308    0\n",
       "Name: sex, Length: 1309, dtype: int64"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# II.2 Put your code here\n",
    "#map male and female\n",
    "df.sex = df.sex.map({'male':0,'female':1})\n",
    "\n",
    "df.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isi null di age\n",
    "df['age'].fillna(df['age'].mean(), inplace= True)\n",
    "df['fare'].fillna(df['fare'].mean(), inplace= True)\n",
    "df.drop(['cabin','embarked'],axis=1,inplace=True)\n",
    "\n",
    "y = df.survived.copy()\n",
    "x = df.drop(['survived'], axis=1)\n",
    "x.drop(['name','ticket','index'],axis=1,inplace=True)\n",
    "\n",
    "x_train , x_val , y_train , y_val = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4yS8O3tyyyh"
   },
   "source": [
    "## II.3\n",
    "Lakukanlah:\n",
    "1. Prediksi dengan menggunakan model Logistic Regression sebagai *baseline*\n",
    "2. Tampilkan evaluasi dari model yang dibangun dari metrics yang anda tentukan pada II.1\n",
    "3. Tampilkan confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "id": "EpEqAz94yyQo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Evaluasi================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.85      0.84       157\n",
      "         1.0       0.77      0.75      0.76       105\n",
      "\n",
      "    accuracy                           0.81       262\n",
      "   macro avg       0.80      0.80      0.80       262\n",
      "weighted avg       0.81      0.81      0.81       262\n",
      "\n",
      "================Confusion Matrix================\n",
      "[[133  24]\n",
      " [ 26  79]]\n"
     ]
    }
   ],
   "source": [
    "# II.3 Put your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "#fit\n",
    "model.fit(x_train, y_train)\n",
    "model.predict(x_val)\n",
    "\n",
    "print(\"================Evaluasi================\")\n",
    "print(classification_report(y_val,model.predict(x_val)))\n",
    "\n",
    "print(\"================Confusion Matrix================\")\n",
    "print(confusion_matrix(y_val,model.predict(x_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFB2AlZfzU54"
   },
   "source": [
    "## II.4 \n",
    "Lakukanlah:\n",
    "1. Pembelajaran dengan model lain\n",
    "2. Hyperparameter tuning model yang kalian pakai dengan menggunakan Grid Search (perhatikan random factor pada beberapa algoritma model)\n",
    "3. Lakukan validasi dengan menggunakan cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\joseg\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\joseg\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\joseg\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "id": "df0YVJ7dzUSc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.479) r2: (test=0.011) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=0.050) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.005) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=-0.018) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.479) r2: (test=0.054) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.462) r2: (test=0.082) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.122) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.467) r2: (test=0.056) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.459) r2: (test=0.061) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.126) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.423) r2: (test=0.229) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.268) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.438) r2: (test=0.171) total time=   1.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.417) r2: (test=0.225) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.270) total time=   1.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.481) r2: (test=0.002) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.055) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.006) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=-0.020) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.060) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.466) r2: (test=0.066) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.130) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.468) r2: (test=0.054) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.058) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.133) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.433) r2: (test=0.192) total time=   1.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.417) r2: (test=0.277) total time=   1.8s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.440) r2: (test=0.163) total time=   1.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.215) total time=   1.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.277) total time=   1.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.481) r2: (test=0.002) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.056) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.003) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.480) r2: (test=-0.027) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=0.058) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.466) r2: (test=0.064) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.129) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.467) r2: (test=0.058) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.463) r2: (test=0.043) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.459) r2: (test=0.130) total time=   1.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.435) r2: (test=0.186) total time=   2.9s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.271) total time=   2.8s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.440) r2: (test=0.164) total time=   2.9s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.430) r2: (test=0.174) total time=   2.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.421) r2: (test=0.268) total time=   3.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.392) r2: (test=0.338) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.386) r2: (test=0.381) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.241) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.381) r2: (test=0.354) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.381) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.373) r2: (test=0.401) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.367) r2: (test=0.440) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.416) r2: (test=0.253) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.362) r2: (test=0.417) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.434) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.364) r2: (test=0.429) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.360) r2: (test=0.461) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.240) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.361) r2: (test=0.418) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.363) r2: (test=0.456) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.403) r2: (test=0.301) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.383) r2: (test=0.391) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.421) r2: (test=0.234) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.331) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.379) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.356) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.368) r2: (test=0.439) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.237) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.390) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.368) r2: (test=0.441) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.389) r2: (test=0.349) total time=   1.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.368) r2: (test=0.437) total time=   1.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.427) r2: (test=0.214) total time=   1.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.375) r2: (test=0.372) total time=   1.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.371) r2: (test=0.430) total time=   1.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.281) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.392) r2: (test=0.362) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.423) r2: (test=0.225) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.405) r2: (test=0.268) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.394) r2: (test=0.360) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.401) r2: (test=0.307) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.384) r2: (test=0.388) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.427) r2: (test=0.212) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.396) r2: (test=0.300) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.381) total time=   1.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.410) r2: (test=0.278) total time=   2.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.396) r2: (test=0.351) total time=   2.9s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.443) r2: (test=0.151) total time=   2.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.254) total time=   2.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.401) r2: (test=0.336) total time=   2.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.368) r2: (test=0.416) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.360) r2: (test=0.461) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.244) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.364) r2: (test=0.411) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.363) r2: (test=0.455) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.409) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.366) r2: (test=0.444) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.416) r2: (test=0.253) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.364) r2: (test=0.408) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.367) r2: (test=0.443) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.411) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.375) r2: (test=0.416) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.244) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.375) r2: (test=0.372) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.376) r2: (test=0.415) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.395) r2: (test=0.330) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.382) r2: (test=0.393) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.431) r2: (test=0.195) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.333) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.384) r2: (test=0.392) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.401) r2: (test=0.309) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.404) r2: (test=0.322) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.444) r2: (test=0.147) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.408) r2: (test=0.259) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.395) r2: (test=0.355) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.401) r2: (test=0.309) total time=   1.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.407) r2: (test=0.312) total time=   1.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.444) r2: (test=0.147) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.256) total time=   1.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.395) r2: (test=0.355) total time=   1.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.412) r2: (test=0.269) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.408) r2: (test=0.308) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.445) r2: (test=0.144) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.221) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.414) r2: (test=0.291) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.412) r2: (test=0.268) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.414) r2: (test=0.287) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.447) r2: (test=0.135) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.221) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.414) r2: (test=0.291) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.412) r2: (test=0.268) total time=   2.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.414) r2: (test=0.287) total time=   2.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.447) r2: (test=0.135) total time=   2.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.221) total time=   2.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.414) r2: (test=0.291) total time=   2.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.355) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.423) r2: (test=0.257) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.117) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.427) r2: (test=0.189) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.397) r2: (test=0.350) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.355) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.432) r2: (test=0.227) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.117) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.427) r2: (test=0.189) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.398) r2: (test=0.345) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.355) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.432) r2: (test=0.227) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.117) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.427) r2: (test=0.189) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.398) r2: (test=0.345) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.122) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.129) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.516) r2: (test=-0.150) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.433) r2: (test=0.164) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.447) r2: (test=0.175) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.122) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.129) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.516) r2: (test=-0.150) total time=   0.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.433) r2: (test=0.164) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.447) r2: (test=0.175) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.452) r2: (test=0.122) total time=   1.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.129) total time=   1.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.516) r2: (test=-0.150) total time=   1.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.433) r2: (test=0.164) total time=   1.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.447) r2: (test=0.175) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.457) r2: (test=0.101) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.456) r2: (test=0.138) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.506) r2: (test=-0.105) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.489) r2: (test=-0.064) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.439) r2: (test=0.203) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.457) r2: (test=0.101) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.456) r2: (test=0.138) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.506) r2: (test=-0.105) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.489) r2: (test=-0.064) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.439) r2: (test=0.203) total time=   1.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.457) r2: (test=0.101) total time=   2.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.456) r2: (test=0.138) total time=   3.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.506) r2: (test=-0.105) total time=   2.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.489) r2: (test=-0.064) total time=   2.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.439) r2: (test=0.203) total time=   2.9s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.479) r2: (test=0.011) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=0.050) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.005) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=-0.018) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.479) r2: (test=0.054) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.462) r2: (test=0.082) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.122) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.467) r2: (test=0.056) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.459) r2: (test=0.061) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.126) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.423) r2: (test=0.229) total time=   1.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.268) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.438) r2: (test=0.170) total time=   1.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.417) r2: (test=0.225) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.420) r2: (test=0.270) total time=   1.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.481) r2: (test=0.002) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.055) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.005) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=-0.019) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.060) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.466) r2: (test=0.066) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.130) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.467) r2: (test=0.056) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.460) r2: (test=0.059) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.133) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.433) r2: (test=0.193) total time=   1.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.417) r2: (test=0.280) total time=   1.7s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.440) r2: (test=0.164) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.218) total time=   2.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.418) r2: (test=0.278) total time=   2.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=0.001) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.477) r2: (test=0.056) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.482) r2: (test=-0.002) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.480) r2: (test=-0.027) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100; neg_root_mean_squared_error: (test=-0.478) r2: (test=0.058) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.466) r2: (test=0.064) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.458) r2: (test=0.130) total time=   1.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.467) r2: (test=0.059) total time=   1.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.463) r2: (test=0.043) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200; neg_root_mean_squared_error: (test=-0.459) r2: (test=0.129) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.436) r2: (test=0.182) total time=   2.6s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.272) total time=   3.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.439) r2: (test=0.165) total time=   3.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.430) r2: (test=0.174) total time=   2.8s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.422) r2: (test=0.265) total time=   2.7s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.392) r2: (test=0.338) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.386) r2: (test=0.381) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.419) r2: (test=0.241) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.381) r2: (test=0.354) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.381) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.373) r2: (test=0.401) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200; neg_root_mean_squared_error: (test=-0.367) r2: (test=0.441) total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "# II.4 Put your code here\n",
    "# Menggunakan Neural Network\n",
    "from xgboost import XGBRegressor\n",
    "modelXGB = XGBRegressor(random_state = 2021)\n",
    "## Grid Search\n",
    "search_space = {\n",
    "    \"n_estimators\" : [100,200,500],\n",
    "    \"max_depth\" : [3,6,9],\n",
    "    \"gamma\" : [0.01 , 0.1],\n",
    "    \"learning_rate\" : [0.001 , 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(\n",
    "    estimator = modelXGB,\n",
    "    param_grid= search_space,\n",
    "    scoring=[\"r2\",\"neg_root_mean_squared_error\"],\n",
    "    refit = \"r2\",\n",
    "    cv = 5,\n",
    "    verbose = 4\n",
    ")\n",
    "GS.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18528/755699300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle = True)\n",
    "kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ePIGuRZuNZb"
   },
   "source": [
    "# III. Improvement\n",
    "Terdapat beberapa metode untuk melakukan peningkatan performa, contohnya adalah:\n",
    "1. Melakukan oversampling / undersampling pada data\n",
    "2. Menggabungkan beberapa model \n",
    "\n",
    "Pada bagian ini, kalian diharapkan dapat:\n",
    "1. Melakukan training dengan data hasil oversampling / undersampling dan melakukan validasi dengan benar\n",
    "2. Memahami beberapa metode untuk menggabungkan beberapa model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGgjXVqf1vhN"
   },
   "source": [
    "## III.1\n",
    "Lakukanlah:\n",
    "1. Oversampling pada kelas minoritas pada data train, kemudian train dengan model *baseline* (II.3), lakukan validasi dengan data validasi. Data train dan validasi adalah data yang kalian bagi pada bagian II.2\n",
    "2. Undersampling pada kelas mayoritas pada data train, kemudian train dengan model *baseline* (II.3) lakukan validasi dengan data validasi. Data train dan validasi adalah data yang kalian bagi pada bagian II.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLLLsyoF2GIM"
   },
   "outputs": [],
   "source": [
    "# III.1 Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtbGHN3P2Fxe"
   },
   "source": [
    "## III.2\n",
    "Lakukanlah:\n",
    "1. Eksplorasi soft voting, hard voting, dan stacking\n",
    "2. Buatlah model Logistic Regression dan SVM (boleh menggunakan model dengan beberapa parameter yang berbeda)\n",
    "3. Lakukanlah soft voting dari model-model yang sudah kalian buat pada poin 2\n",
    "4. Lakukan hard voting dari model-model yang sudah kalian buat pada poin 2\n",
    "5. Lakukanlah stacking dengan final classifier adalah Logistic Regression dari model-model yang sudah kalian buat pada poin 2\n",
    "6. Lakukan validasi dengan metrics yang kalian tentukan untuk poin 3, 4, dan 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfGqy72SAZ-t"
   },
   "source": [
    "Put your answer for section III.2 point 1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdchguBQtErx"
   },
   "outputs": [],
   "source": [
    "# III.2 Put your code here\n",
    "modelLR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unmFXb-73OMD"
   },
   "source": [
    "# IV. Analisis\n",
    "Bandingkan hasil dari:\n",
    "1. Model Baseline (II.3)\n",
    "2. Model lain (II.4)\n",
    "3. Hasil undersampling\n",
    "4. Hasil oversampling\n",
    "5. Hasil soft voting\n",
    "6. Hasil hard voting\n",
    "7. Hasil stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9x0VH2AAkwZ"
   },
   "source": [
    "Put your answer for section IV here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Pendahuluan IF3270.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
